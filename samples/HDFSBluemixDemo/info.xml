<?xml version="1.0" encoding="UTF-8"?>
<info:toolkitInfoModel xmlns:common="http://www.ibm.com/xmlns/prod/streams/spl/common" xmlns:info="http://www.ibm.com/xmlns/prod/streams/spl/toolkitInfo">
  <info:identity>
    <info:name>TestForBluemix</info:name>
    <info:description>This sample contains applications that can run within the StreamingAnalytics service and connect to a Hadoop instance also running on Bluemix.
There are 3 composites in this project:
* hdfsexample::TestWrite
* hdfsexample::TestRead
* hdfsexample::TestDirScan.
Each composite tests one of the HDFS* operators: HDFS2FileSink, HDFS2FileSource, and HDFS2DirectoryScan respectively. 
It is suggested to run the `hdfsexample::TestWrite` composite first in order for the remaining applications to run successfully.

# Pre-compiled Binaries for Bluemix
Each composite has been compiled and the resulting .sab files are in the `deploy` directory.  
These applications are ready to be submitted as jobs in the Streaming Analytics service in Bluemix so you can quickly verify that they work with your BigInsights service.  See &quot;Running the samples&quot; below for more information.


# Compiling the samples
Compiling in Streams Studio:
1. Start Streams Studio
2. In Streams Explorer view, add the &quot;com.ibm.streamsx.hdfs&quot; toolkit as one of the toolkit locations
3. From the main menu, select File -> Import.
4. Select General ->Existing Project into Workspace
5. Browse to the location of the HDFSBluemixDemo project and select it
6. Once the sample is imported, wait for the build to finish.  If autobuild is turned off, select resulting project, right click -> Build Project



Compiling at the command line:
1. Create a directory. For example, you can create a directory in your home directory. 
2. Copy the `samples` folder to this directory.
3. Build the sample applications. Go to the `HDFSBluemixDemo` subdirectory and run `make`. By default, the sample is compiled as a distributed application. If you want to compile the application as a standalone application, run `make standalone` instead. Run `make clean` to revert the samples back to their original uncompiled state.



# Running the samples from Streams Studio.
Follow the instructions to compile above.  Once the project is built, select the main composite of the sample, right click -> Launch Active Build Config 

# Running using the Streaming Analytics service:
 * Go to the Application Dashboard in your browser and click &quot;submit job&quot;.  
 * Browse to the deploy folder if using the pre compiled files or to the output/Distributed folder and upload the .sab file to the service.
 * Specify the uri, username and password as submission parameters.

# Running from the command line:

* Running in standalone mode: 
  * From the samples directory, run the following command:
  
   `./output/Standalone/hdfsexample::&lt;TestToRun>/bin/standalone hdfsUri=&quot;webhdfs://&lt;machine_name>:&lt;port>&quot; hdfsUser=&quot;&lt;user_name>&quot; hdfsPassword=&quot;&lt;password>&quot;` 
* Running in distributed mode:  
  * If using a local installation of Streams, start your IBM InfoSphere Streams instance, then use the `streamtool` command to submit the .adl files that were generated during the application build: 

   `streamtool submitjob -i &lt;instance_name> output/Distributed/hdfsexample::TestDirScan/hdfsexample.TestDirScan.adl -P hdfsUri=&quot;webhdfs://&lt;machine_name>:&lt;port>&quot; -P hdfsUser=&quot;&lt;user_name>&quot; -P hdfsPassword=&quot;&lt;password>&quot;`
</info:description>
    <info:version>1.0.0</info:version>
    <info:requiredProductVersion>4.1.0.0</info:requiredProductVersion>
  </info:identity>
  <info:dependencies>
    <info:toolkit>
      <common:name>com.ibm.streamsx.hdfs</common:name>
      <common:version>[2.1.0,3.0.0)</common:version>
    </info:toolkit>
  </info:dependencies>
</info:toolkitInfoModel>