namespace application;
/**
 * This application shows how to use the HDFS toolkit to connect to a Hadoop instance running on Bluemix
 */
use com.ibm.streamsx.hdfs::*;

composite TestReadFromHDFSOnBluemix {
param
	///specify the filename to write to at submission time. 
	//default is to create a new file every time and add the timestamp to the file name so a new file is created every time
		expression<rstring> $file: getSubmissionTimeValue("file", "/tmp/hdfs_test_%TIME.txt");
		expression<rstring> $user : getSubmissionTimeValue("user");
		expression<rstring> $password : getSubmissionTimeValue("password");
		expression<rstring> $uri :getSubmissionTimeValue("uri"); //format webhdfs://host:port
	
graph
stream <rstring line> Input = Beacon() {
 	param
 		iterations: 10;
 	output 
 		Input : line = "HDFS and Streams on Bluemix Test: New LINE " + (rstring) IterationCount();
 }
 
 stream<rstring out_file_name, uint64 size>  Sink = HDFS2FileSink(Input) {
 	param
		file : $file ; 
		hdfsUri : $uri ;
		hdfsUser:$user;
		hdfsPassword: $password;
 	
 }
 stream<rstring fileName> Functor1 = Functor(Sink) {
 	output
 		Functor1 : fileName = out_file_name;
 }
 stream <rstring line> FromHDFS = HDFS2FileSource(Functor1) {
 	param
		hdfsUri : $uri ;
		//Use the keystore related parameters if you have a trust store containing the certificate for the server
		//keyStorePassword:"pass";  
		//keyStorePath: "etc/store.jks";
		hdfsPassword: $password;
		hdfsUser:$user;
  }
 stream <rstring line> C1 = Custom(FromHDFS) {
 
 	logic
 		onTuple FromHDFS: {
 			printStringLn("Output read from remote file: " + line);
 		}
 }
}


 

